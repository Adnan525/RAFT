{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce0bae75-bf27-4862-9ce8-e5d63b437e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from raft_util import get_doc_chunk, generate_qa_pair, process_qa_pair\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "openai_token = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a423f073-b4ef-4c3a-9ba0-67c35c7475fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai model\n",
    "llm = OpenAI(temperature=0, n=1, model=\"gpt-3.5-turbo\", api_key=openai_token)\n",
    "embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92283791-2e57-48c0-90be-9a26b362f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document chunk\n",
    "docs = get_doc_chunk(\"./text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "372faecb-8473-45d8-9a38-b3e4073f50da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs) ## this is before truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da6419ff-9b6c-4695-9943-e6b559acc3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This eBook is for the use of anyone anywhere in the United States and most     other parts of the world at no cost and with almost no restrictions     whatsoever. You may copy it, give it away or re-use it under the terms     of the Project Gutenberg License included with this eBook or online     at www.gutenberg.org. If you     are not located in the United States, you will have to check the laws     of the country where you are located before using this eBook.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1462786-3d11-4673-995f-4efb6c91bbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who are Tardo and Peo in \"DISQUALIFIED\" by Charles L. Fontenay?',\n",
       " '0',\n",
       " 'What is the significance of the castle overlooking the area in \"DISQUALIFIED\" by Charles L. Fontenay?',\n",
       " '0',\n",
       " 'Who entertained Tardo and Peo at luncheon?',\n",
       " '1',\n",
       " 'What was served for dessert?',\n",
       " '1',\n",
       " 'What technical aid is available aboard the ship?',\n",
       " '2',\n",
       " 'What kind of equipment will not be received until a more thorough investigation is conducted?',\n",
       " '2',\n",
       " 'What are some fundamental requirements for colonies in other star systems?',\n",
       " '3',\n",
       " 'What difficulties have faced colonies in other star systems?',\n",
       " '3',\n",
       " 'What is the reason why the ship just rusted away?',\n",
       " '4',\n",
       " 'Who is the first ship to land on the planet since colonization?',\n",
       " '4',\n",
       " 'What were the main difficulties faced by the colonizers on the planet?',\n",
       " '5',\n",
       " 'Why did the colonizers know the planet was habitable before landing on it?',\n",
       " '5',\n",
       " 'What did the colonists do to make the planet liveable?',\n",
       " '6',\n",
       " 'Was slavery used by the colonists in this society?',\n",
       " '6',\n",
       " 'What were the colonists anxious to cooperate on?',\n",
       " '7',\n",
       " 'What did Tardo base his conclusions on?',\n",
       " '7',\n",
       " 'What do some people think about the pay of certain individuals?',\n",
       " '8',\n",
       " 'Where did the concept of a union come from in this culture?',\n",
       " '8',\n",
       " 'What kind of community did Tardo and the two men visit?',\n",
       " '9',\n",
       " 'What types of trades were being practiced in the village nearby?',\n",
       " '9',\n",
       " 'What kind of training did the Council agent have?',\n",
       " '10',\n",
       " 'What factors would Tardo consider significant during the inspection?',\n",
       " '10',\n",
       " 'What was Tardo most intent on?',\n",
       " '11',\n",
       " 'What was the reason for having to walk on the planet?',\n",
       " '11',\n",
       " 'What is the reason for the lack of technology development on the planet?',\n",
       " '12',\n",
       " 'Who is responsible for working the fields on the planet?',\n",
       " '12',\n",
       " 'Who typically works the fields in the village?',\n",
       " '13',\n",
       " 'What is the reason for the lack of workers in the fields?',\n",
       " '13',\n",
       " 'Why did Tardo decide against recommending technical aid for the world?',\n",
       " '14',\n",
       " 'What were Tardo and Peo doing as Alpha Persei was sinking in the western sky?',\n",
       " '14',\n",
       " 'What are the two classes of people on the planet according to Tardo?',\n",
       " '15',\n",
       " 'Why does Tardo recommend against aid at this time?',\n",
       " '15',\n",
       " 'What was the challenge faced by colonizing ships 1000 years ago?',\n",
       " '16',\n",
       " 'Why did colonizing ships have to depend on native animal life of the planet they landed on?',\n",
       " '16',\n",
       " 'What did Saranta say?',\n",
       " '17',\n",
       " \"What is the context of Tardo's remark?\",\n",
       " '17']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get old questions\n",
    "old_questions = []\n",
    "with open(\"questions.txt\", \"r\") as f:\n",
    "    old_questions = f.readlines()\n",
    "    # old_questions = [question.strip() for i, question in enumerate(f.readlines()) if i % 3 == 0 or i % 2 == 0]\n",
    "\n",
    "target = []\n",
    "for i, line in enumerate(old_questions):\n",
    "    if i % 3 == 0:\n",
    "        target.append(line.strip())\n",
    "        target.append(old_questions[i+2].strip())\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e71e913-74bb-4bd7-9e03-485c260c00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "def generate_cot_answer(llm:OpenAI, question:str, context:str) -> str:\n",
    "    # print(context)\n",
    "    prompt = f\"\"\"\n",
    "        Question: {question}\\nContext: {context}\\n\n",
    "        Answer the question using the information given in the context above or your own knowledge if context is irrelevant. \n",
    "        Here is things to pay attention to:\n",
    "        - First analyse the given context.\n",
    "        - You must identify any part of the context that is not relevant to answer the question.\n",
    "        - Provide step-by-step reasoning on how to answer the question.\n",
    "        - In the reasoning, if you need to copy paste some sentences from the context, include them in ##begin_quote## and ##end_quote##. This would mean that things outside of ##begin_quote## and ##end_quote## are not directly copy paste from the context.\n",
    "        - End your response with final answer in the form <ANSWER>: $answer, the answer should be succinct.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        ChatMessage(\n",
    "            role=\"system\",\n",
    "            content=\"You are a helpful assistant who can provide an answer given a question and relevant context.\",\n",
    "        ),\n",
    "        ChatMessage(role=\"user\", content=prompt),\n",
    "    ]\n",
    "    return str(llm.chat(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3228a03-995d-4b5c-8ba0-b70dbc3ed811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33e297a71e6463e801460af60c15a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate CoT answer for each question\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "with open(\"raft_some_o_c.txt\", \"w\") as raft_file:\n",
    "    for i, line in tqdm(enumerate(target)):\n",
    "        # if a question generate CoT\n",
    "        if i%2 == 0:\n",
    "            # question\n",
    "            raft_file.write(line + \"\\n\")\n",
    "            raft_file.write(\"=\"*5 + \"\\n\")\n",
    "\n",
    "            # adding context\n",
    "            chunk_index = int(target[i+1])\n",
    "            true_context = docs[chunk_index]\n",
    "            o_c_context = docs[random.randrange(35, 75)]\n",
    "            raft_file.write(true_context + \"\\n\" + o_c_context + \"\\n\")\n",
    "            raft_file.write(\"=\"*5 + \"\\n\")\n",
    "            \n",
    "            # cot answer\n",
    "            cot = generate_cot_answer(llm, line, true_context + \"\\n\" + o_c_context)\n",
    "            # print(cot)\n",
    "            raft_file.write(cot + \"\\n\")\n",
    "            raft_file.write(\"=\"*5 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03bcaca5-6b86-4218-af4a-46f0861a7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using regex cause i forgot to add \\n after context\n",
    "## regex (?<!^)====="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
