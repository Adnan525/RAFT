{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9927553c-722b-4193-8719-8c8f030bd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from raft_util import get_doc_chunk, generate_qa_pair, process_qa_pair\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "openai_token = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "928507df-27e7-46b3-b29a-ec1572941a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai model\n",
    "llm = OpenAI(temperature=0, n=1, model=\"gpt-3.5-turbo\", api_key=openai_token)\n",
    "embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50911de9-fc02-4824-9288-ae4d011af609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document chunk\n",
    "docs = get_doc_chunk(\"./text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbe87c64-95c7-4fe3-91eb-5c555c60f24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['What is the capital of France?',\n",
       "  'What is the capital of Japan?',\n",
       "  'What is the capital of Canada?',\n",
       "  'What is the capital of Australia?',\n",
       "  'What is the capital of Azerbaijan?',\n",
       "  'What is the capital of Italy?',\n",
       "  'What is the capital of Bangladesh?',\n",
       "  'What is the capital of Egypt?',\n",
       "  'What is the capital of Russia?',\n",
       "  'What is the starting square of the white king in standard chess?',\n",
       "  'How many pieces does each player start with in a game of chess?',\n",
       "  \"What is the term for a move that puts the opponent's king in immediate threat of capture?\",\n",
       "  'What is the only piece that can jump over other pieces in chess?',\n",
       "  'How many squares are in a chess board?',\n",
       "  'What is the move called when a king and a rook move at the same time?',\n",
       "  'Which piece is considered the most powerful on the chessboard?',\n",
       "  'What is it called when a pawn reaches the opposite side of the board and is promoted to a higher piece?',\n",
       "  'Who wrote the play \"Romeo and Juliet\"?',\n",
       "  'Who painted the Mona Lisa?',\n",
       "  'Who developed the theory of relativity?',\n",
       "  'What is the tallest mountain in the world?',\n",
       "  'Who was the first President of the United States?',\n",
       "  'In which year did the Titanic sink?',\n",
       "  'What is the largest ocean on Earth?'],\n",
       " 24)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of context questions\n",
    "all_questions = []\n",
    "with open(\"text/out_of_context_questions.txt\", \"r\") as f:\n",
    "    all_questions = f.readlines()\n",
    "\n",
    "all_questions = [question.split(\"=====\")[0].strip() for question in all_questions]\n",
    "\n",
    "all_questions, len(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06cbe4e4-21ef-40b6-b42d-87a4bfb5c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the cot answer prompt slightly to emphasize reasoning\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "def generate_cot_answer(llm:OpenAI, question:str, context:str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "        Question: {question}\\nContext: {context}\\n\n",
    "        Answer this question using the information given in the context above, or your own knowledge if context is irrelevant. \n",
    "        Here is things to pay attention to:\n",
    "        - First provide step-by-step reasoning on how to answer the question from the context.\n",
    "        - In the reasoning, if you need to copy paste some sentences from the context, include them in ##begin_quote## and ##end_quote##. This would mean that things outside of ##begin_quote## and ##end_quote## are not directly copy paste from the context.\n",
    "        - Clealry mention if the context's not relevant to the question and which part is not relevant.\n",
    "        - End your response with final answer in the form <ANSWER>: $answer, the answer should be succinct.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        ChatMessage(\n",
    "            role=\"system\",\n",
    "            content=\"You are a helpful assistant who can provide an answer given a question and context.\",\n",
    "        ),\n",
    "        ChatMessage(role=\"user\", content=prompt),\n",
    "    ]\n",
    "    return str(llm.chat(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5e39866-71ac-43e0-9468-cb6a859eb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will pass question no as chunk index\n",
    "# generate CoT answer for each question\n",
    "with open(\"raft_o_c.txt\", \"w\") as raft_file:\n",
    "    for i, line in enumerate(all_questions):\n",
    "        raft_file.write(line + \"\\n\")\n",
    "        raft_file.write(\"=\"*5 + \"\\n\")\n",
    "        raft_file.write(generate_cot_answer(llm, line, docs[i]) + \"\\n\")\n",
    "        raft_file.write(\"=\"*5 + \"\\n\")\n",
    "        raft_file.write(docs[i] + \"\\n\")\n",
    "        raft_file.write(\"=\"*5 + \"\\n\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
